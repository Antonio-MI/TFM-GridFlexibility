{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import GRU\n",
    "from keras.layers import TimeDistributed\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner import Hyperband\n",
    "from keras_tuner import BayesianOptimization\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Funciones_Cons.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruebas(interval, block, variable_mode, n_obs_antes, n_pred):\n",
    "    res_time = interval\n",
    "    edificio = block\n",
    "    variables = variable_mode\n",
    "    data = pd.read_csv('data-model-consumo' + edificio + '-' + res_time + '.csv', sep=\";\", index_col=0)\n",
    "    \n",
    "    if variables == 1:\n",
    "        data = data[['dif_cons', 'V4']]\n",
    "    else: \n",
    "        data = data.drop(columns='Fecha')\n",
    "    df = data\n",
    "    \n",
    "    per_train = 0.7\n",
    "    per_test = 0.15  \n",
    "    train, test, val, scaler_x, scaler_y = split_dataset(df.values, per_train, per_test)\n",
    "    \n",
    "    n_input = n_obs_antes\n",
    "    n_out = 1\n",
    "    steps_pred = n_pred\n",
    "    train_x, train_y = to_supervised(train, n_input, n_out, steps_pred)\n",
    "    test_x, test_y = to_supervised(test, n_input, n_out, steps_pred)\n",
    "    val_x, val_y = to_supervised(val, n_input, n_out, steps_pred)\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\n",
    "    def build_model(hp):\n",
    "        model = Sequential()\n",
    "        hp_units = hp.Choice('input_unit',[32,64,128])\n",
    "        model.add(GRU(units = hp_units, input_shape=(n_timesteps, n_features)))\n",
    "        model.add(RepeatVector(n_outputs))   \n",
    "        for i in range(hp.Int('n_layers', 1, 2)):\n",
    "            units_i = hp.Choice(f'dense_{i}_units',[32,64,128])\n",
    "            model.add(GRU(units = units_i, return_sequences=True))\n",
    "        hp_dropout = hp.Float('Dropout_rate',min_value=0,max_value=0.4,step=0.1)\n",
    "        model.add(Dropout(hp_dropout))\n",
    "        model.add(TimeDistributed(Dense(units = hp_units)))\n",
    "        model.add(TimeDistributed(Dense(n_outputs)))\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        model.compile(loss='mae', optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "        return model\n",
    "    \n",
    "    tuner= BayesianOptimization(build_model,\n",
    "                                 objective='val_loss', max_trials=15, num_initial_points=2, seed = 123, overwrite=True)\n",
    "\n",
    "    stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10)\n",
    "    tuner.search(x=train_x, y=train_y, epochs=200, batch_size=128, validation_data=(val_x,val_y), verbose=2,\n",
    "            shuffle=False, callbacks=[stop_early])\n",
    "    model = tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    prediction = model.predict(test_x)\n",
    "    prediction = prediction.reshape(prediction.shape[0],prediction.shape[1])\n",
    "    prediction = scaler_y.inverse_transform(prediction)\n",
    "    test_y = scaler_y.inverse_transform(test_y)\n",
    "    \n",
    "    cvrmse, r2, rmse = metrics(test_y, prediction)\n",
    "    \n",
    "    return model, cvrmse, r2, rmse, test_y, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 46s]\n",
      "val_loss: 0.2148205190896988\n",
      "\n",
      "Best val_loss So Far: 0.17817559838294983\n",
      "Total elapsed time: 00h 11m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "obs_antes = [1,2,4]  #1,2,4\n",
    "pred_steps = 1    #1\n",
    "block = ['A','B','C']\n",
    "interval = ['60T','120T']\n",
    "var_mode = [1,2] #1 = dif_cons + V4, #2 = all\n",
    "\n",
    "for i in block:\n",
    "    for j in interval:\n",
    "        for k in obs_antes:\n",
    "            for l in var_mode:\n",
    "                model, cvrmse, r2, rmse, test_y, prediction = pruebas(j, i, l, k, pred_steps)\n",
    "                model.save('model_cons_gru_' + i + '_0'+ str(l) + '_pred' + j + '_prev' + str(k) + '.h5')\n",
    "                results_metrics = pd.read_csv('model-cons-results_metrics.csv', sep=\";\")\n",
    "                add_metrics = {'Modelo': 'GRU', 'Edificio': i,'Variables': '0'+str(l), 'pred': j, 'n_obs_antes': k, 'CVRMSE': cvrmse, 'R2': r2, 'RMSE': rmse}\n",
    "                results_metrics = results_metrics.append(add_metrics, ignore_index = True)\n",
    "                results_metrics.to_csv('model-cons-results_metrics.csv', sep=\";\", index=False)\n",
    "                results_preds = pd.read_csv('model-cons-results_preds.csv', sep=\";\")\n",
    "                prediction = prediction.round(2)\n",
    "                add_preds = pd.DataFrame({'Prueba': np.repeat('GRU-' + i + '-' + str(l) + '-' + j +'-' + str(k), len(test_y)),\n",
    "                                        'test_y': test_y.tolist(),'prediction': prediction.tolist()})\n",
    "                results_preds = pd.concat([results_preds, add_preds])\n",
    "                results_preds.to_csv('model-cons-results_preds.csv', sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
