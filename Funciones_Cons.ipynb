{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, per_train, per_test):\n",
    "    df = data\n",
    "    train = df[0:int(np.ceil(df.shape[0]*per_train))]\n",
    "    val = df[int(np.ceil(df.shape[0]*per_train)): int(np.ceil(df.shape[0]*(per_train+per_test)))]\n",
    "    test = df[int(np.ceil(df.shape[0]*(per_train+per_test))):]\n",
    "    #Escalado en train y test por separado. Si no se hace aquí ya no se puede porque todo lo que sigue es con arrays 3D\n",
    "    scaler_y = StandardScaler()\n",
    "    train_y = scaler_y.fit_transform(train[:,0].reshape(-1, 1))\n",
    "    val_y = scaler_y.fit_transform(val[:,0].reshape(-1, 1))\n",
    "    test_y = scaler_y.transform(test[:,0].reshape(-1, 1))\n",
    "    scaler_x = StandardScaler()\n",
    "    train_x = scaler_x.fit_transform(train[:,1:]) \n",
    "    val_x = scaler_x.fit_transform(val[:,1:]) \n",
    "    test_x = scaler_x.transform(test[:,1:])\n",
    "    \n",
    "    #Rehacemos los DataFrames con los datos escalados para poder hacer el split\n",
    "    train = pd.concat([pd.DataFrame(train_y),pd.DataFrame(train_x)], axis=1)\n",
    "    test = pd.concat([pd.DataFrame(test_y),pd.DataFrame(test_x)], axis=1)\n",
    "    val = pd.concat([pd.DataFrame(val_y),pd.DataFrame(val_x)], axis=1)\n",
    "\n",
    "    train = array(train)\n",
    "    test = array(test)\n",
    "    val = array(val)\n",
    "    return train, test, val, scaler_x, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_out, steps_pred):\n",
    "    # Ponemos los datos en 2D: una entrada para cada muestra y paso de tiempo con las n características\n",
    "    data = train#.reshape((train.shape[0]*train.shape[1], train.shape[2])) \n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # Pasamos por todo el conjunto de datos, de step en step\n",
    "    for _ in range(len(data)):\n",
    "        # Definimos cuando empieza el input, cuando acaba, e igual para el output\n",
    "        # En este caso el output empieza cuando acaba el input\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # Iteramos mientras haya ejemplos\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :]) # X son todas las variables en t\n",
    "            y.append(data[in_end:out_end, 0])  # y es la temperatura en t+1 (si n_out=1) #AQUÍ SE DEFINE EL LAG\n",
    "        # Pasamos al siguiente instante de tiempo\n",
    "        in_start += steps_pred\n",
    "    X = array(X)\n",
    "    y = array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(datos_test_x, datos_test_y, n_input, modelo, steps, features):\n",
    "    test_y = datos_test_y\n",
    "    test_x = datos_test_x\n",
    "    n_timesteps=steps\n",
    "    n_features=features\n",
    "    #Creamos una lista vacía para las predicciones\n",
    "    predictions = list()\n",
    "    #Ponemos el índice i a 0\n",
    "    i=0\n",
    "    for i in range(len(test_x)):\n",
    "        data = test_x[i,:,:]\n",
    "        input_x = data.reshape((1, n_timesteps, n_features))\n",
    "        \n",
    "        # Prediccion para cada paso de tiempo\n",
    "        yhat = model.predict(input_x, verbose=0)\n",
    "        yhat_sequence = yhat[0] \n",
    "\n",
    "        # Guardamos las predicciones\n",
    "        predictions.append(yhat_sequence)\n",
    "        \n",
    "        if i < len(test_x):\n",
    "            try: test_x[i+1,n_input,0] = yhat[0]\n",
    "            except IndexError: continue\n",
    "        else: break\n",
    "            \n",
    "    predictions = array(predictions)\n",
    "    \n",
    "    return predictions, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(test_y, prediction):\n",
    "    rmse = np.sqrt(mean_squared_error(test_y,prediction))\n",
    "    cvrmse = rmse/np.mean(test_y)*100\n",
    "    r2 = r2_score(test_y, prediction)\n",
    "    return cvrmse, r2, rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
